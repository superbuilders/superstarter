---
title: Groq
product: vercel
url: /docs/agent-resources/integrations-for-models/groq
type: conceptual
prerequisites:
  - /docs/agent-resources/integrations-for-models
  - /docs/agent-resources
related:
  []
summary: Learn about groq on Vercel.
---

# Vercel Groq Integration

&#x20;is a high-performance AI inference
service with an ultra-fast Language Processing Unit (LPU) architecture. It
enables fast response times for language model inference, making it ideal for
applications requiring low latency.

## Use cases

You can use the [Vercel and Groq integration](https://vercel.com/marketplace/groq) to:

- Connect AI models such as Whisper-large-v3 for audio processing and Llama models for text generation to your Vercel projects.
- Deploy and run inference with optimized performance.

### Available models

Groq provides a diverse range of AI models designed for high-performance tasks.

## More resources


---

[View full sitemap](/docs/sitemap)
